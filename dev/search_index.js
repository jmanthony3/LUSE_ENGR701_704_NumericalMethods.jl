var documenterSearchIndex = {"docs":
[{"location":"","page":"Home","title":"Home","text":"CurrentModule = NumericalMethods","category":"page"},{"location":"#NumericalMethods","page":"Home","title":"NumericalMethods","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for NumericalMethods.","category":"page"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"#Functions","page":"Home","title":"Functions","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Modules = [NumericalMethods]","category":"page"},{"location":"#NumericalMethods.InitialValueProblem","page":"Home","title":"NumericalMethods.InitialValueProblem","text":"InitialValueProblem(f, a, b, h, α, N)\n\nStructure of the boundary conditions to Initial-Value Problem (IVP) differential equation.\n\nNotes\n\nMake sure the independent variable (e.g. time) is the first argument of f!\n\n\n\n\n\n","category":"type"},{"location":"#NumericalMethods.SingleVariableIteration","page":"Home","title":"NumericalMethods.SingleVariableIteration","text":"SingleVariableIteration(f, a, b, n, tol)\n\nGiven f(p) such that p ∈ [a, b], find the root of a single-variable equation in so many iterations, n within tolerance, tol.\n\n\n\n\n\n","category":"type"},{"location":"#NumericalMethods.bezier-Union{Tuple{T}, NTuple{4, T}} where T<:(AbstractVector{T} where T)","page":"Home","title":"NumericalMethods.bezier","text":"bezier(x, y, xguides, yguides)\n\nAn application of Hermitic polynomials to draw Bezier curves between points.\n\nNotes\n\nEach argument should be a one-to-one mapping of points, (xᵢ, yᵢ) and (xᵢ₊₁, yᵢ₊₁) and their respective guide points, (xᵢ⁺, yᵢ⁺) and (xᵢ₊₁⁻, yᵢ₊₁⁻).\n\n\n\n\n\n","category":"method"},{"location":"#NumericalMethods.bisection-Tuple{SingleVariableIteration}","page":"Home","title":"NumericalMethods.bisection","text":"bisection(svi::SingleVariableIteration)\n\nRoot-finding method: f(x) = 0. Search for solution by halving the bounds such that a and b initially yield opposite signs in function.\n\nNotes\n\nRelying on the Intermediate Value Theorem (IVT), this is a bracketed, root-finding method. This method is rather slow to converge but will always converge to a solution; therefore, is a good starter method.\n\n\n\n\n\n","category":"method"},{"location":"#NumericalMethods.clamped-Union{Tuple{T}, Tuple{T, T, T}} where T<:Vector{Float64}","page":"Home","title":"NumericalMethods.clamped","text":"clamped(x, f, fp)\n\nThe bookend polynomials will have the same slope entering and exiting the interval as the derivative at the respective endpoint.\n\n\n\n\n\n","category":"method"},{"location":"#NumericalMethods.endpoint-Union{Tuple{T}, Tuple{T, T, Real, Symbol}} where T<:Vector{Float64}","page":"Home","title":"NumericalMethods.endpoint","text":"endpoint(x, f, h, point[; method=:three])\n\nFind the derivative of a bookend point at either :begin or :end of dataset. Acceptable values for method include {:three, :five}.\n\n\n\n\n\n","category":"method"},{"location":"#NumericalMethods.false_position-Tuple{SingleVariableIteration, Float64, Float64}","page":"Home","title":"NumericalMethods.false_position","text":"false_position(svi::SingleVariableIteration, p0, p1)\n\nAttempt root-finding method with initial guesses such that p0 and p1 in [a, b] yield opposite signs in function.\n\nUse function with lowest slope!\n\nNotes\n\nSimilar to, but slower to converge than, the secant_method() by including a test to ensure solution is root-bracketed.\n\nSee fixed_point() for theorem.\n\n\n\n\n\n","category":"method"},{"location":"#NumericalMethods.fixed_point-Tuple{SingleVariableIteration, Float64}","page":"Home","title":"NumericalMethods.fixed_point","text":"fixed_point(svi::SingleVariableIteration, p0)\n\nAttempt root-finding method with initial guess, p0 in [a, b] by solving the equation g(p) = p via f(p) - p = 0.\n\nUse function with lowest slope!\n\nNot root-bracketed.\n\nNotes\n\nTheorem:\n\nExistence of a fixed-point:  If g ∈ C[a,b] and g(x) ∈ C[a, b] for all x ∈ [a, b], then function, g has a fixed point, p ∈ [a, b].\nUniqueness of a fixed point:  If g'(x) exists on [a, b] and a positive constant, k < 1 exist with {|g'(x)| ≤ k | x ∈ (a, b)}, then there is exactly one fixed-point, p ∈ [a, b].\n\nConverges by mathcal{O}(text{linear}) if g'(p) ≠ 0, and mathcal{O}(text{quadratic}) if g'(p) = 0 and g''(p) < M, where M = g''(ξ) that is the error function.\n\n\n\n\n\n","category":"method"},{"location":"#NumericalMethods.integrate-Tuple{Union{Function, AbstractVector{T} where T}, AbstractVector{T} where T}","page":"Home","title":"NumericalMethods.integrate","text":"integrate(f, x      [; rule=:trapezoidal, tol=10^-3])\nintegrate(f, a, b, h[; rule=:trapezoidal, tol=10^-3])\nintegrate(f, a, b, n[; rule=:trapezoidal, tol=10^-3])\n\nFind the definite integral by some numerical quadrature.\n\nNotes\n\nf may be a function or range. The domain may be defined with a vector, x or on the interval [a, b] either by number of sub-intervals, n or step-size, h. rule accepts {:trapezoidal (default), :midpoint, :simpson13, :simpson38, :simpsonN}. Dataset may contain unevenly spaces points.\n\nReferences\n\nhttps://en.wikipedia.org/wiki/Simpson%27s_rule\n\n\n\n\n\n","category":"method"},{"location":"#NumericalMethods.lagrange-Union{Tuple{T}, Tuple{T, T}} where T<:Vector{Float64}","page":"Home","title":"NumericalMethods.lagrange","text":"lagrange(x, f[; n=nothing])\n\nGiven a domain, x and range, f, construct the nth Lagrangian polynomial.\n\nNotes\n\nIf n=nothing, then method will utilize entire dataset. Polynomials will quickly oscillate for larger datasets.\n\n\n\n\n\n","category":"method"},{"location":"#NumericalMethods.linearleastsquares-Union{Tuple{T}, Tuple{T, T, Integer}} where T<:(AbstractVector{T} where T)","page":"Home","title":"NumericalMethods.linearleastsquares","text":"linearleastsquares(x, f, n::Integer)\n\nConstruct a polynomial of degree, n while minimizing the least squares error.\n\nNotes\n\nLeast squares error := E = sum_i=1^my_i - P_n(x_i)^2\n\nConstructed polynomial of the form: P(x) = a_nx^n + a_n - 1x^n - 1 + dots + a_1x + a_0\n\n\n\n\n\n","category":"method"},{"location":"#NumericalMethods.linearleastsquares-Union{Tuple{T}, Tuple{T, T, Symbol}} where T<:(AbstractVector{T} where T)","page":"Home","title":"NumericalMethods.linearleastsquares","text":"linearleastsquares(x, f, type::Symbol)\n\nGiven a domain and range, yield the coefficients for an equation and the equation of the form y = ax^b.\n\n\n\n\n\n","category":"method"},{"location":"#NumericalMethods.maximum_iterations","page":"Home","title":"NumericalMethods.maximum_iterations","text":"maximum_iterations(obj, method[, p0=0])\n\nFind greatest integer for maximum iterations within tolerance.\n\nNotes\n\nAcceptable values for method ∈ {:bisection, :fixed_point, :newton_raphson, :secant_method, :false_position}. Initial guess, p0 for function solution is not needed for :bisection method.\n\n\n\n\n\n","category":"function"},{"location":"#NumericalMethods.maximum_slope-Tuple{SingleVariableIteration}","page":"Home","title":"NumericalMethods.maximum_slope","text":"maximum_slope(svi::SingleVariableIteration)\n\nFind the greatest value for first derivative of function.\n\n\n\n\n\n","category":"method"},{"location":"#NumericalMethods.midpoint-Union{Tuple{T}, Tuple{T, T, Real, Integer}} where T<:Vector{Float64}","page":"Home","title":"NumericalMethods.midpoint","text":"midpoint(x, f, h, point[; method=:three])\n\nFind the derivative of some point within a dataset. Acceptable values for method include {:three, :five, :2nd}.\n\n\n\n\n\n","category":"method"},{"location":"#NumericalMethods.n1derivative-Union{Tuple{T}, Tuple{T, T, Integer}} where T<:Vector{Float64}","page":"Home","title":"NumericalMethods.n1derivative","text":"n1derivative(x, f, j[; n=nothing])\n\nThe general (n + 1)-point formula to approximate f' at point j.\n\nNotes\n\nIf n = nothing, then entire dataset used to construct nth Lagrange coefficient.\n\n\n\n\n\n","category":"method"},{"location":"#NumericalMethods.natural-Union{Tuple{T}, Tuple{T, T}} where T<:Vector{Float64}","page":"Home","title":"NumericalMethods.natural","text":"natural(x, f)\n\nThe bookend polynomials do not assume the slope entering and exiting the interval as the derivative at the respective endpoint.\n\n\n\n\n\n","category":"method"},{"location":"#NumericalMethods.newton_raphson-Tuple{SingleVariableIteration, Float64}","page":"Home","title":"NumericalMethods.newton_raphson","text":"newton_raphson(svi::SingleVariableIteration, p0[; df=nothing])\n\nAttempt root-finding method with initial guess, p0 in [a, b] by solving the equation g(p) = p via f(p) - p = 0. df will be the first derivative of function if not given.\n\nUse function with lowest slope!\n\ndf(x) ≠ 0\n\nNotes\n\nQuickest convergence rate, but not root-bracketed and has trouble with symmetric functions! Initial guess, p0 must be close to real solution; else, will converge to different root or oscillate (if symmetric). This method can be viewed as fixed-point iteration.\n\nTechnique based on first Taylor polynomial expansion of f about p{0} (that is p0) and evaluated at x = p. |p - p{0}| is assumed small; therefore, 2^{\text{nd}}-order Taylor term, the error, is small.\n\nSee fixed_point() for theorem.\n\n\n\n\n\n","category":"method"},{"location":"#NumericalMethods.newtondifference-Union{Tuple{T}, Tuple{T, T, Float64}} where T<:Vector{Float64}","page":"Home","title":"NumericalMethods.newtondifference","text":"newtondifference(x, f, α[; dir::Symbol=:auto])\n\nGiven a domain, x and range, f, construct some polynomial by Newton's Divided Difference centered around α. :forward or :backward construction.\n\nNotes\n\nDirection will be chosen if not specified. Polynomials best made with even spacing in x; although, this is not completely necessary.\n\n\n\n\n\n","category":"method"},{"location":"#NumericalMethods.secant_method-Tuple{SingleVariableIteration, Float64, Float64}","page":"Home","title":"NumericalMethods.secant_method","text":"secant_method(svi::SingleVariableIteration, p0, p1)\n\nAttempt root-finding method with initial guesses such that p0 and p1 in [a, b] yield opposite signs in function.\n\nUse function with lowest slope!\n\nNot root-bracketed.\n\nNotes\n\nMethod is less computationally expensive than newton_raphson() but may converge at slower rate by circumventing need to calculate derivative.\n\nSee fixed_point() for theorem.\n\n\n\n\n\n","category":"method"},{"location":"#NumericalMethods.solve-Tuple{InitialValueProblem}","page":"Home","title":"NumericalMethods.solve","text":"solve(ivp::InitialValueProblem[; method=:forward_euler, tol=10^-3])\n\nSolve ivp according to method ∈ {:forward_euler (default), :backward_euler, :improved_euler, :modified_euler, :runge_kutta}.\n\nNotes\n\nEach method has an equivalent convenience function. E.g. solve(ivp; method=:runge_kutta) ≡ runge_kutta(ivp).\n\n\n\n\n\n","category":"method"},{"location":"#NumericalMethods.solve-Union{Tuple{SingleVariableIteration}, Tuple{T}} where T<:Float64","page":"Home","title":"NumericalMethods.solve","text":"solve(svi::SingleVariableIteration[; method=:bisection, p0, p1, df])\n\nAttempt to find where f(p) = 0 according to method ∈ {:bisection (default), :fixed_point, :newton_raphson, :secant_method, :false_position}. Each method also has a convenience function.\n\nNotes\n\nConvergence Rates:     :newton_raphson > :secant_method > :false_position > :fixed_point > :bisection\n\n:bisection is default because will always converge to a solution but is not the quickest.\n\n\n\n\n\n","category":"method"},{"location":"#Index","page":"Home","title":"Index","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"","category":"page"}]
}
